Download Ollama:

$ curl -fsSL https://ollama.com/install.sh | sh

          
***********************************************

Run llama3.2 (Smallest official LLaMA)
Highly optimized
Very small compared to full LLaMA3
Good for classification tasks
Runs well on normal CPUs

Run:

$ ollama run llama3.2