{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cf56d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12e94da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "                                                text       author\n",
      "0         To be, or not to be, that is the question.  Shakespeare\n",
      "1  All the world's a stage, and all the men and w...  Shakespeare\n",
      "2  Some are born great, some achieve greatness, a...  Shakespeare\n",
      "3  It is a truth universally acknowledged, that a...       Austen\n",
      "4  I declare after all there is no enjoyment like...       Austen\n",
      "5  A lady's imagination is very rapid; it jumps f...       Austen\n",
      "6  It was the best of times, it was the worst of ...      Dickens\n",
      "7                     Please, sir, I want some more.      Dickens\n",
      "8  No one is useless in this world who lightens t...      Dickens\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'text': [\n",
    "        # Shakespeare\n",
    "        \"To be, or not to be, that is the question.\",\n",
    "        \"All the world's a stage, and all the men and women merely players.\",\n",
    "        \"Some are born great, some achieve greatness, and some have greatness thrust upon them.\",\n",
    "        # Jane Austen\n",
    "        \"It is a truth universally acknowledged, that a single man in possession of a good fortune must be in want of a wife.\",\n",
    "        \"I declare after all there is no enjoyment like reading!\",\n",
    "        \"A lady's imagination is very rapid; it jumps from admiration to love, from love to matrimony in a moment.\",\n",
    "        # Charles Dickens\n",
    "        \"It was the best of times, it was the worst of times.\",\n",
    "        \"Please, sir, I want some more.\",\n",
    "        \"No one is useless in this world who lightens the burden of it for anyone else.\"\n",
    "    ],\n",
    "    'author': [\n",
    "        'Shakespeare', 'Shakespeare', 'Shakespeare',\n",
    "        'Austen', 'Austen', 'Austen',\n",
    "        'Dickens', 'Dickens', 'Dickens'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Dataset Preview:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6e5a3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and Feature Extraction\n",
    "X = df['text']\n",
    "y = df['author']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Convert text to numerical features\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1421abe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Shakespeare\n",
       "8        Dickens\n",
       "2    Shakespeare\n",
       "4         Austen\n",
       "3         Austen\n",
       "6        Dickens\n",
       "Name: author, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "906bdc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Evaluation:\n",
      "Accuracy: 0.3333333333333333\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.50      1.00      0.67         1\n",
      "     Dickens       0.00      0.00      0.00         1\n",
      " Shakespeare       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.17      0.33      0.22         3\n",
      "weighted avg       0.17      0.33      0.22         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/.pyenv/versions/3.13.1/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/dev/.pyenv/versions/3.13.1/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/dev/.pyenv/versions/3.13.1/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Train a Naive Bayes Model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Step 5 — Evaluate Model\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"\\nModel Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e743b4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Predictions:\n",
      "\n",
      "Text: O Romeo, Romeo! wherefore art thou Romeo?\n",
      "→ Predicted Author: Austen\n",
      "\n",
      "Text: It was a bright cold day in April, and the clocks were striking thirteen.\n",
      "→ Predicted Author: Austen\n",
      "\n",
      "Text: Vanity and pride are different things, though the words are often used synonymously.\n",
      "→ Predicted Author: Austen\n",
      "\n",
      "Text: To be, or not to be, that is the question.\n",
      "→ Predicted Author: Shakespeare\n"
     ]
    }
   ],
   "source": [
    "# Test the Model on New Samples\n",
    "samples = [\n",
    "    \"O Romeo, Romeo! wherefore art thou Romeo?\",\n",
    "    \"It was a bright cold day in April, and the clocks were striking thirteen.\",\n",
    "    \"Vanity and pride are different things, though the words are often used synonymously.\",\n",
    "    \"To be, or not to be, that is the question.\"\n",
    "]\n",
    "\n",
    "sample_features = vectorizer.transform(samples)\n",
    "predictions = model.predict(sample_features)\n",
    "\n",
    "print(\"\\nSample Predictions:\")\n",
    "for text, author in zip(samples, predictions):\n",
    "    print(f\"\\nText: {text}\\n→ Predicted Author: {author}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae2133d",
   "metadata": {},
   "source": [
    "### Project Implementation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4857e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c843fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb6b7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in full dataset: 51939\n",
      "Samples after selecting 5 authors: 27684\n",
      "author\n",
      "Jane Austen        13873\n",
      "Herman Melville     7788\n",
      "Shakespeare         3078\n",
      "John Milton         1728\n",
      "Lewis Carroll       1217\n",
      "Name: count, dtype: int64\n",
      "Total Samples: 27684\n",
      "                                                text       author\n",
      "0  [Emma by Jane Austen 1816]\\n\\nVOLUME I\\n\\nCHAP...  Jane Austen\n",
      "1  She was the youngest of the two daughters of a...  Jane Austen\n",
      "2  Her mother\\nhad died too long ago for her to h...  Jane Austen\n",
      "3  Sixteen years had Miss Taylor been in Mr. Wood...  Jane Austen\n",
      "4  Between _them_ it was more the intimacy\\nof si...  Jane Austen\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load saved dataset\n",
    "df = pd.read_csv(\"gutenberg_authors_dataset.csv\")\n",
    "print(\"Total samples in full dataset:\", len(df))\n",
    "\n",
    "# Choose 5 authors\n",
    "selected_authors = [\n",
    "    \"Jane Austen\",\n",
    "    \"Shakespeare\",\n",
    "    \"Herman Melville\",\n",
    "    \"Lewis Carroll\",\n",
    "    \"John Milton\"\n",
    "]\n",
    "\n",
    "# Filter for selected authors\n",
    "df = df[df['author'].isin(selected_authors)]\n",
    "print(\"Samples after selecting 5 authors:\", len(df))\n",
    "print(df['author'].value_counts())\n",
    "\n",
    "# Prepare text and label lists\n",
    "texts = df['text'].tolist()\n",
    "authors = df['author'].tolist()\n",
    "\n",
    "print(\"Total Samples:\", len(texts))\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0899b8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing \n",
    "def preprocess(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens if w.isalpha() and w not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['clean_text'] = df['text'].apply(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5aab339",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['clean_text'], df['author'], test_size=0.3, random_state=42, stratify=df['author']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cb22146",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [] \n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "count_vec = CountVectorizer(ngram_range=(1,2), stop_words='english')\n",
    "X_train_count = count_vec.fit_transform(X_train)\n",
    "X_test_count = count_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2435174f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes (TF-IDF)\n",
      "Accuracy: 0.834\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Herman Melville       0.86      0.81      0.83      2337\n",
      "    Jane Austen       0.80      0.99      0.88      4162\n",
      "    John Milton       0.99      0.29      0.45       518\n",
      "  Lewis Carroll       1.00      0.09      0.17       365\n",
      "    Shakespeare       0.99      0.77      0.87       924\n",
      "\n",
      "       accuracy                           0.83      8306\n",
      "      macro avg       0.93      0.59      0.64      8306\n",
      "   weighted avg       0.86      0.83      0.81      8306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes + TF-IDF\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_nb_tfidf = nb_tfidf.predict(X_test_tfidf)\n",
    "acc_nb_tfidf = accuracy_score(y_test, y_pred_nb_tfidf)\n",
    "results.append((\"Naive Bayes (TF-IDF)\", acc_nb_tfidf))\n",
    "\n",
    "print(\"Naive Bayes (TF-IDF)\")\n",
    "print(\"Accuracy:\", round(acc_nb_tfidf, 3))\n",
    "print(classification_report(y_test, y_pred_nb_tfidf, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eea8a032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes (CountVectorizer)\n",
      "Accuracy: 0.895\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Herman Melville       0.91      0.86      0.88      2337\n",
      "    Jane Austen       0.87      0.99      0.93      4162\n",
      "    John Milton       0.92      0.77      0.84       518\n",
      "  Lewis Carroll       1.00      0.36      0.53       365\n",
      "    Shakespeare       0.99      0.84      0.91       924\n",
      "\n",
      "       accuracy                           0.90      8306\n",
      "      macro avg       0.94      0.76      0.82      8306\n",
      "   weighted avg       0.90      0.90      0.89      8306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes + CountVectorizer\n",
    "nb_count = MultinomialNB()\n",
    "nb_count.fit(X_train_count, y_train)\n",
    "\n",
    "y_pred_nb_count = nb_count.predict(X_test_count)\n",
    "acc_nb_count = accuracy_score(y_test, y_pred_nb_count)\n",
    "results.append((\"Naive Bayes (CountVectorizer)\", acc_nb_count))\n",
    "\n",
    "print(\"Naive Bayes (CountVectorizer)\")\n",
    "print(\"Accuracy:\", round(acc_nb_count, 3))\n",
    "print(classification_report(y_test, y_pred_nb_count, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a16e84f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (TF-IDF)\n",
      "Accuracy: 0.886\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Herman Melville       0.86      0.87      0.87      2337\n",
      "    Jane Austen       0.88      0.97      0.92      4162\n",
      "    John Milton       0.93      0.64      0.76       518\n",
      "  Lewis Carroll       0.98      0.56      0.71       365\n",
      "    Shakespeare       0.97      0.80      0.88       924\n",
      "\n",
      "       accuracy                           0.89      8306\n",
      "      macro avg       0.92      0.77      0.83      8306\n",
      "   weighted avg       0.89      0.89      0.88      8306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression + TF-IDF\n",
    "log_tfidf = LogisticRegression(max_iter=1000)\n",
    "log_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_log_tfidf = log_tfidf.predict(X_test_tfidf)\n",
    "acc_log_tfidf = accuracy_score(y_test, y_pred_log_tfidf)\n",
    "results.append((\"Logistic Regression (TF-IDF)\", acc_log_tfidf))\n",
    "\n",
    "print(\"Logistic Regression (TF-IDF)\")\n",
    "print(\"Accuracy:\", round(acc_log_tfidf, 3))\n",
    "print(classification_report(y_test, y_pred_log_tfidf, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b3b3d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (CountVectorizer)\n",
      "Accuracy: 0.885\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Herman Melville       0.90      0.83      0.86      2337\n",
      "    Jane Austen       0.86      0.98      0.91      4162\n",
      "    John Milton       0.95      0.70      0.80       518\n",
      "  Lewis Carroll       0.95      0.65      0.77       365\n",
      "    Shakespeare       0.96      0.80      0.87       924\n",
      "\n",
      "       accuracy                           0.89      8306\n",
      "      macro avg       0.92      0.79      0.85      8306\n",
      "   weighted avg       0.89      0.89      0.88      8306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression + CountVectorizer\n",
    "log_count = LogisticRegression(max_iter=1000)\n",
    "log_count.fit(X_train_count, y_train)\n",
    "\n",
    "y_pred_log_count = log_count.predict(X_test_count)\n",
    "acc_log_count = accuracy_score(y_test, y_pred_log_count)\n",
    "results.append((\"Logistic Regression (CountVectorizer)\", acc_log_count))\n",
    "\n",
    "print(\"Logistic Regression (CountVectorizer)\")\n",
    "print(\"Accuracy:\", round(acc_log_count, 3))\n",
    "print(classification_report(y_test, y_pred_log_count, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef3d813e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Predictions:\n",
      "\n",
      "Text: O Romeo, Romeo! wherefore art thou Romeo?\n",
      "→ Predicted Author: Shakespeare\n",
      "\n",
      "Text: It was a bright cold day in April, and the clocks were striking thirteen.\n",
      "→ Predicted Author: Jane Austen\n",
      "\n",
      "Text: Vanity and pride are different things, though the words are often used synonymously.\n",
      "→ Predicted Author: Jane Austen\n",
      "\n",
      "Text: To be, or not to be, that is the question.\n",
      "→ Predicted Author: Jane Austen\n"
     ]
    }
   ],
   "source": [
    "# test sample for Naive Bayes (CountVectorizer)\n",
    "samples = [\n",
    "    \"O Romeo, Romeo! wherefore art thou Romeo?\",\n",
    "    \"It was a bright cold day in April, and the clocks were striking thirteen.\",\n",
    "    \"Vanity and pride are different things, though the words are often used synonymously.\",\n",
    "    \"To be, or not to be, that is the question.\"\n",
    "]\n",
    "\n",
    "sample_features = count_vec.transform(samples)\n",
    "predictions = nb_count.predict(sample_features)\n",
    "\n",
    "print(\"\\nSample Predictions:\")\n",
    "for text, author in zip(samples, predictions):\n",
    "    print(f\"\\nText: {text}\\n→ Predicted Author: {author}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c72771c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Predictions:\n",
      "\n",
      "Text: O Romeo, Romeo! wherefore art thou Romeo?\n",
      "→ Predicted Author: Shakespeare\n",
      "\n",
      "Text: It was a bright cold day in April, and the clocks were striking thirteen.\n",
      "→ Predicted Author: Herman Melville\n",
      "\n",
      "Text: Vanity and pride are different things, though the words are often used synonymously.\n",
      "→ Predicted Author: Jane Austen\n",
      "\n",
      "Text: To be, or not to be, that is the question.\n",
      "→ Predicted Author: Jane Austen\n"
     ]
    }
   ],
   "source": [
    "# test sample for Logistic Regression (CountVectorizer)\n",
    "sample_features = count_vec.transform(samples)\n",
    "predictions = log_count.predict(sample_features)\n",
    "\n",
    "print(\"\\nSample Predictions:\")\n",
    "for text, author in zip(samples, predictions):\n",
    "    print(f\"\\nText: {text}\\n→ Predicted Author: {author}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb1ac40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
